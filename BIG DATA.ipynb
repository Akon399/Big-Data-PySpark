{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2c0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes & Lecture by Akhona Njeje.\n",
    "# Date 13 July 2023.\n",
    "# Topic : BIG DATA.\n",
    "\n",
    "\n",
    "\n",
    "# Notes.\n",
    "\n",
    "### Hadoop.\n",
    "\n",
    "### What is Hadoop? Mapreduce? Spark? & PySpark?\n",
    "### Local vs Distributed Systems.\n",
    "\n",
    "### So far weve worked with data that can fit in our ram 8gb. But what if we want to go beyond?\n",
    "### We need to employ distributed systems, its like having multiple computers.\n",
    "### A local system only uses computational resources of a single machine.\n",
    "### Adistribured process has access to the computational resources across a number of machines.\n",
    "\n",
    "### Distributed systems can easily scale.\n",
    "### Hadoop = Distributed Systems.\n",
    "### Hadoop, helps with distributing large files across multiple machines.\n",
    "\n",
    "### Hadoop uses a tool called Hadoop Distributed File System(HDFS).\n",
    "### Hadoop also uses Mapreduce, wich allows computation on the data.\n",
    "### HDFS = Distribute large files, Mapreduce = Computational Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5721fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark.\n",
    "\n",
    "### Spark is one of the latest tools we use to handle big data.\n",
    "### Spark can be used as an alternative to Mapreduce.\n",
    "### Spark is 100x faster than Mapreduce.\n",
    "\n",
    "### To set up Spark you need to setup AWS / or any cloud provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a91d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS acc set up.\n",
    "\n",
    "### https://aws.amazon.com/free.\n",
    "### https://docs.aws.amazon.com/AmazonSimpleDB/latest/DeveloperGuide/AboutAWSAccounts.html\n",
    "### We need EC2.\n",
    "\n",
    "### EC2 is a cloud computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20cc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC2 set up.\n",
    "\n",
    "### Your PC <---> SSH <---> EC2.\n",
    "### SSH(Secure Shell Connection).\n",
    "### more info --->https://\n",
    "###               www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/learn/lecture/5784218#overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4606e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark.\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9939cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile example.txt\n",
    "first line\n",
    "second line\n",
    "third line\n",
    "fourth line\n",
    "\n",
    "textFile = sc.textFile('example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3225e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6649d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d29637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
